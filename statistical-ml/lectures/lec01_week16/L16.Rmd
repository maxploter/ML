---
title: "L16"
output: html_notebook
---
## Mathematical Statistics
## Computer lab
# Author: Kaur Lumiste


```{r}
# Data and working with data ----
load(url("https://github.com/Rkursus/sygis2019/raw/master/data/students.RData"))
```



# Some commands for data set summary information, try them:
```{r}
head(students)
tail(students)
summary(students)
names(students)
```


# Extract a single variable using the “$” sign after the data set name and then the name of the variable:
```{r}
students$height
```

# Skip repeating the “students$” part and tell R that we are using the data set "students". 
# This is achieved with the attach(.) command
```{r}
attach(students)
```


# Try now
```{r}
plot(height, SVR)

plot(height, weight)
mean(height)
median(height)
table(health)
prop.table(table(health))
round(prop.table(table(health))*100,2)
boxplot(height~gender)
ftable(gender, beer, health)
```



# Linear regression -------


# Model on blood pressure and height
```{r}
model1 = lm( SVR ~ height )
summary(model1) 
```


# Check model assumptions
```{r}
plot(model1)
```

# or
```{r}
par(mfrow = c(2,2))
plot(model1)
```



# Correlations ----
```{r}
cor(data.frame(weight, height, SVR, DVR), use="pairwise.complete.obs")

cor(data.frame(weight, height, SVR, DVR), use="complete.obs")
```
```{r}
d2 = students[complete.cases(data.frame(weight, height, SVR, DVR)),]
dim(d2)
```



# Visualising correlations
```{r}
library("corrplot")

correlations=cor(data.frame(weight, height, SVR, DVR), 
                 use="pairwise.complete.obs")

corrplot(correlations)
corrplot(correlations, method="square")
corrplot(correlations, method="ellipse")
corrplot(correlations, method="number")
corrplot.mixed(correlations)
```



# Testing for normality ----

## Histogram of student weight
```{r}
hist(weight)
```


# or
```{r}
hist(weight, freq=FALSE)
curve(dnorm(x, mean=mean(weight, na.rm=T),
            sd=sd(weight, na.rm=T)), add=T)
```


# or

```{r}
sort(weight)
```



```{r}
qqnorm(weight)
qqline(weight)
```
# or
```{r}
ks.test(weight, 'pnorm')
```

#Shapiro - Will normality test
```{r}
shapiro.test(weight) # H0 data is normally distributed
```

# # Note about Kelngorey - Snoirnov test

#Classical test, present SPSS, Excel and so on
#PROBLEM: test is derived for comparig to a NORTAL DISTRIBUTION with KNOWN PARAMETERS sigma, mu

#We don't know, we estimate - it is not correct to use KS test
#### We shoudl Kolmogorov Smirnov test witih Lilliefors correction
```{r}
lillie.test(weight)
```
#HO is rejected, p < 0.001
#| What to do if data not normal?
# > key assumption does not hold,
# OLS Parameter estimates are still unbiased and BLUE (best unbiased linear estimator)
# best in the sense of having the smallest variance
## problem is that the confidence intervals are incorrect under non-normality ## and so as well the significance tests
### Solutions? = normalizing transform - go with natural log (or sqrt, or inverse)

```{r}
hist(log(weight), freq=FALSE)
curve(dnorm(x, mean=mean(weight, na.rm=T),
            sd=sd(weight, na.rm=T)), add=T)
```
```{r}
par(mfrow=c(2,1))
hist(weight[gender==1], xlim=c(40, 120))
hist(weight[gender==2], xlim=c(40, 120))
```
```{r}
shapiro.test(weight[gender==1])

shapiro.test(weight[gender==2]) # we don't reject normality
```
##### IN the regression context:
#1) Take log of the weight variable
#2) Add gender to the regression model = multivariate regression (not in this course)

```{r}
gender = factor(gender)
```


```{r}
m = lm(SVR~log(weight))
summary(m)

m2 = lm(SVR~log(weight) + gender)
summary(m2)
```

```{r}
hist(m$residuals)
```

```{r}
hist(m2$residuals)
```
```{r}
shapiro.test(m$residuals)
shapiro.test(m2$residuals)
```


```{r}
shapiro.test(m$residuals)
shapiro.test(m2$residuals) 
```


