{"cells":[{"cell_type":"markdown","metadata":{"id":"gaKkRHHNWKsE"},"source":["## Homework 6: Image Classification with Pytorch\n","\n","The homework consists of two parts: theoretical part and coding part.\n","\n"," - All theoretical questions must be answered in your own words, do not copy-paste text from the internet. Points can be deducted for terrible formatting or incomprehensible English.\n"," - Code must be commented. If you use code you found online, you have to add the link to the source you used. There is no penalty for using outside sources as long as you convince us you understand the code.\n","\n","**Note that coding part consists of two different notebooks.**\n","\n","*Once completed zip the entire directory containing this exercise and upload it to https://courses.cs.ut.ee/2024/nn/spring/Main/Practices.*"]},{"cell_type":"markdown","metadata":{"id":"Ow0wQUxQcO6N"},"source":["## **Google colab introduction**"]},{"cell_type":"markdown","metadata":{"id":"jMcAUN8ccPYa"},"source":["For HW6 and HW7 to make installations easier and to utilize GPU for your NN trainings you can use google colab. \n","\n","Google Colab is a free, web-based tool that allows users to write and execute Python code in their browser. It is similar to Jupyter Notebook and provides a virtual machine with a GPU and pre-installed libraries, making it easy to set up and run complex code without having to install software locally. It also allows users to share and collaborate on code with others, making it a useful tool for students working on group projects or learning together."]},{"cell_type":"markdown","metadata":{"id":"YADqPxP0WLXU"},"source":["## **Part 1: Theory Exercises**\n","\n","These theoretical questions are about the material covered in the lecture about \"Recurrent Neural Networks\"."]},{"cell_type":"markdown","metadata":{"id":"TBYT7U1zWLf7"},"source":["**Task 1.1:** \n","\n","Recurrent networks: basic truths and architectures\n","\n","Which of the following is true about recurrent neural networks. In case of ”True” bring\n","an example (e.g. suffices to refer to a slide in lecture), in case of ”False”, explain.\n"]},{"cell_type":"markdown","metadata":{"id":"-cG6yH-pjRbs"},"source":["1. A recurrent network always produces one output prediction per timestep."]},{"cell_type":"markdown","metadata":{"id":"yv-P5vqAjRwX"},"source":["<font color='blue'>Answer for question 1</font>: "]},{"cell_type":"markdown","metadata":{"id":"pUZwYmc5jR9K"},"source":["2. It is possible to put a convolutional layer between the input and the recurrent layer."]},{"cell_type":"markdown","metadata":{"id":"Au8nk67KjSHo"},"source":["<font color='blue'>Answer for question 2</font>: "]},{"cell_type":"markdown","metadata":{"id":"IpySv1BajSSD"},"source":["3. The final layer (that makes the classification/regression) must be connected directly to the recurrent layer."]},{"cell_type":"markdown","metadata":{"id":"cqAiq0WrjSci"},"source":["<font color='blue'>Answer for question 3</font>: "]},{"cell_type":"markdown","metadata":{"id":"8NU-6QPOj-g9"},"source":["4. In all RNNs types seen in the lecture, output produced at timestep t can only depend on inputs received at timesteps 0 to t, and not on future timesteps."]},{"cell_type":"markdown","metadata":{"id":"ZPdLRitYj-nm"},"source":["<font color='blue'>Answer for question 4</font>: "]},{"cell_type":"markdown","metadata":{"id":"ebyf3m_zj-qV"},"source":["5. All layers of a recurrent neural network are recurrent."]},{"cell_type":"markdown","metadata":{"id":"GXlT2nExj-s3"},"source":["<font color='blue'>Answer for question 5</font>: "]},{"cell_type":"markdown","metadata":{"id":"0oO_f1cwj-vw"},"source":["6. Only one layer of the recurrent network can be recurrent (two recurrent layers would make no sense)."]},{"cell_type":"markdown","metadata":{"id":"GobYFTQkj-8U"},"source":["<font color='blue'>Answer for question 6</font>: "]},{"cell_type":"markdown","metadata":{"id":"xY9_0XNfj-_I"},"source":["7. The activations of the hidden nodes stay the same across all timesteps."]},{"cell_type":"markdown","metadata":{"id":"gcA6lIBDj_BC"},"source":["<font color='blue'>Answer for question 7</font>: "]},{"cell_type":"markdown","metadata":{"id":"ptqhDZACkRtT"},"source":["8. Different timesteps use the exact same weight matrices only in recurrent layers. This does not apply to other layers."]},{"cell_type":"markdown","metadata":{"id":"SIXgFU6bkRwL"},"source":["<font color='blue'>Answer for question 8</font>: "]},{"cell_type":"markdown","metadata":{"id":"_rMUMzDIkRzR"},"source":["9. Different timesteps use the exact same weight matrices. This applies to all layers."]},{"cell_type":"markdown","metadata":{"id":"ctQtuS8MkR-w"},"source":["<font color='blue'>Answer for question 9</font>: "]},{"cell_type":"markdown","metadata":{"id":"VAsHdt4skYYN"},"source":["10. Gradient clipping is important to battle against gradients getting weaker and weaker."]},{"cell_type":"markdown","metadata":{"id":"f-er1Jq1kYa4"},"source":["<font color='blue'>Answer for question 10</font>: "]},{"cell_type":"markdown","metadata":{"id":"jCcRAdmhkYdO"},"source":["11. LSTM networks deal with long term dependencies better than simple RNNs, because they have less parameters."]},{"cell_type":"markdown","metadata":{"id":"hi5-KDb-kYfv"},"source":["<font color='blue'>Answer for question 11</font>: "]},{"cell_type":"markdown","metadata":{"id":"l5Mt_zo5kd9G"},"source":["12. The gates in LSTM are opened or closed depending on the current input and current hidden state and it does not matter which timestep it currently is."]},{"cell_type":"markdown","metadata":{"id":"kc921LU4kd_d"},"source":["<font color='blue'>Answer for question 12</font>: "]},{"cell_type":"markdown","metadata":{"id":"hQO-xAJvkgtn"},"source":["13. I have trained my network to predict the weather on the 8th day based on the weather of previous 7 days. I now have weather from only past 5 days available. I can still use the same network to predict weather tomorrow (accuracy might be bad, but we can use fewer inputs without changing the network)."]},{"cell_type":"markdown","metadata":{"id":"kQw1U9T4kgwW"},"source":["<font color='blue'>Answer for question 13</font>: "]},{"cell_type":"markdown","metadata":{"id":"Y05MHeXAkgzK"},"source":["14. I can train a recurrent network to receive input only at the first timestep and then produce arbitrarily long sequence of outputs."]},{"cell_type":"markdown","metadata":{"id":"bYRPn-rckni6"},"source":["<font color='blue'>Answer for question 14</font>: "]},{"cell_type":"markdown","metadata":{"id":"pvG-02KLWuDu"},"source":["## **Practical Exercises**\n","\n","You've written a lot of code in this course to provide a whole host of neural network functionality. Dropout, Batch Norm, and 2D convolutions are some of the workhorses of deep learning in computer vision. You've also worked hard to make your code efficient and vectorized.\n","\n","For the last part of the course, though, we're going to leave behind your beautiful codebase and instead migrate to a popular deep learning framework: [PyTorch](https://pytorch.org/). **PyTorch** is an open-source machine learning framework for Python. PyTorch is known for its dynamic computational graph, which allows for more flexibility and faster development, as well as its ability to run on both CPUs and GPUs. "]},{"cell_type":"markdown","metadata":{"id":"ov_W-TpfZdAZ"},"source":["### **Installation**"]},{"cell_type":"markdown","metadata":{"id":"o6GWq8leZdK8"},"source":["If you work with **google colab online**, everything you need from installation tutorial is to run the following line (that starts with !) which will install pytorch. After that you can jump to **Loading Data** section.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fxeNkMi_dc7c"},"outputs":[],"source":["### For Google Colab runs only\n","!pip install torch torchvision"]},{"cell_type":"markdown","metadata":{"id":"QV5d-qhYZdWV"},"source":["If you work with **Jupyter Notebook locally**, we recomend to create a separate environment for your neural network homeworks (if you didn't do it already). It is important now, since you can't have both tensorflow and pytorch in the same environment. If you installed tensorflow before, you need to uninstall it or create a separate environment for pytrorch.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"llSjdrnyf_R_"},"source":["**A reminder!**\n","Here are instructions to create a new Python environment with Anaconda and install PyTorch and Jupyter Notebook in that environment:\n","\n","1. Open the terminal or Anaconda prompt by searching for it in the start menu. \n","2. Create a new environment by running the following command:\n","\n","```\n","conda create --name myenv\n","```\n","You can replace \"myenv\" with the name of your choice for the environment.\n","3. Activate the new environment by running:\n","\n","```\n","conda activate myenv\n","```\n","4. **Install PyTorch** and the Jupyter Notebook by running the following command:\n","```\n","conda install pytorch torchvision -c pytorch\n","```\n","To confirm the installation, you can check the version of PyTorch by running:\n","```\n","python -c \"import torch; print(torch.__version__)\"\n","```\n","If you created new environmen you should install other libraries that you used in previous homeworks too (numpy, pandas, matplotlib). \n","5. Now you can launch the Jupyter Notebook by running:\n","```\n","jupyter notebook\n","```\n","6. After you finished with homework to exit the conda environment in your terminal, you can use the command:\n","```\n","conda deactivate\n","```\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"RxMzk7sph0jX"},"source":["If you had your neural networks existed environment just follow steps 3-6."]},{"cell_type":"markdown","metadata":{"id":"oiOv3b2hiADN"},"source":["### **Loading Data**\n","\n","PyTorch's *torchvision* package provides a collection of utility functions and datasets for computer vision tasks, like loading and transforming image and video datasets. The *torchvision.datasets* module includes popular datasets such as CIFAR, MNIST, etc. and it is a helpful tool for loading and transforming these datasets for use in training deep learning models.\n","\n","When you first use a dataset, PyTorch will download the dataset from the internet and store it in a location specified by the *root* argument in the dataset class's constructor, so that the dataset can be reused in the future without re-downloading it."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2738,"status":"ok","timestamp":1679315322079,"user":{"displayName":"Marharyta Domnich","userId":"04158549936249535345"},"user_tz":-120},"id":"DpZKqz4fWLr-","outputId":"79a10de1-901d-46f7-fdb6-28c9cafcde21"},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Train data shape:  25000\n","Test data shape:  10000\n"]}],"source":["from torchvision import datasets, transforms\n","import torch\n","\n","# Load the CIFAR-10 dataset using torchvision\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","\n","# Shorten the dataset for quicker training\n","# feel free to comment those out if you have GPU\n","train_data = torch.utils.data.Subset(train_data, range(25000))\n","\n","print('Train data shape: ', len(train_data))\n","print('Test data shape: ', len(test_data))"]},{"cell_type":"markdown","metadata":{"id":"ZqYFO86vr_uj"},"source":["After loading the CIFAR-10 dataset, let's use sklearn and do a train-validation split. After that we can create DataLoader objects with torchvision for the training and validation sets. "]},{"cell_type":"markdown","metadata":{"id":"PVKYdtgssg_M"},"source":["A **DataLoader** in PyTorch is a utility class that helps with loading and preprocessing datasets in a way that is efficient and easy to manage. It is an essential component of the PyTorch ecosystem, which helps with:\n","1. Batching: DataLoader allows you to easily create mini-batches of data for training or evaluation. This is crucial for training deep learning models, as processing the entire dataset at once can consume a large amount of memory and may not be feasible.\n","\n","2. Shuffling: During training, DataLoader can shuffle the data, which helps to prevent the model from learning any specific order in the dataset. This improves the generalization capability of the model.\n","\n","3. Parallelism: DataLoader supports parallel loading of data using multiple worker processes, which can speed up data loading and preprocessing, especially when working with large datasets.\n","\n","4. Custom data handling: DataLoader works with custom Dataset classes that you define. This makes it easy to work with a wide variety of data sources and formats, and to apply custom preprocessing or augmentation.\n","\n","5. Memory management: DataLoader handles memory management efficiently by loading data in chunks (batches) and allowing PyTorch to use its internal memory management system to optimize memory usage."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VdZkZZfCr1C3"},"outputs":[],"source":["import torch.utils.data as data\n","from sklearn.model_selection import train_test_split\n","\n","torch.manual_seed(0)\n","\n","# Split the training data into training and validation sets \n","train_data_split, val_data_split = train_test_split(train_data, test_size=0.1)\n","\n","# Create DataLoader objects for the training and validation sets\n","train_loader = data.DataLoader(train_data_split, batch_size=32, shuffle=True)\n","val_loader = data.DataLoader(val_data_split, batch_size=32, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"jQoV9xIoi6GC"},"source":["## First model in PyTorch"]},{"cell_type":"markdown","metadata":{"id":"5zVLxvo-mGkC"},"source":["Before writing our first network with PyTorch, it is important to take a look at [documentation](https://pytorch.org/docs/stable/nn.html#convolution-layers) first. \n","\n","For example, if we want to apply 2d Convolution layer take a look at [this page](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d) which has not only parameters explanations, but mathematical representation of layer and parameters and code usage example.\n","\n","You can take a look at [Loss Functions](https://pytorch.org/docs/stable/nn.html#loss-functions).\n","\n","Optimizers are called with [torch.optim](https://pytorch.org/docs/stable/optim.html?highlight=torch+optim#module-torch.optim) package which support various optimization algorithms.\n","\n","Finally, there are some tutorials, such as [Build the neural network](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html).\n"]},{"cell_type":"markdown","metadata":{"id":"g3hdpnSQjXsR"},"source":["In PyTorch, we define the model as a class inherited from *nn.Module* where we can define the layers and the forward method which defines the forward pass of the model."]},{"cell_type":"markdown","metadata":{"id":"3Dcfc82__DoP"},"source":["**Task 2.1:** \n","\n","Calculate output size after Conv2d layer which should be an input to next Linear layer."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mtymN2r0dcI-"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Define the neural network model as a class that inherits from nn.Module\n","class MyModel(nn.Module):\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","\n","        # Define the layers and their configurations\n","        self.conv1 = nn.Conv2d(3, 32, kernel_size=7, stride=2)\n","        self.act1 = nn.ReLU()\n","        self.flatten = nn.Flatten()\n","\n","        ##############################################################################\n","        # TODO: Calculate output size after Conv2D layer. Use your knowledge from    #\n","        # hw5. output = (input + 2*padding - kernel) // stride + 1                   #\n","        ##############################################################################\n","        conv_output_size = \n","        ##############################################################################\n","        #                             END OF YOUR CODE                               #\n","        ##############################################################################\n","\n","        self.fc = nn.Linear(conv_output_size, 10)  # task to calculate the size\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        # Define the forward pass computations\n","        x = self.conv1(x)\n","        x = self.act1(x)\n","        x = self.flatten(x)\n","        x = self.fc(x)\n","        x = self.softmax(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vc36tsY-WLvB"},"outputs":[],"source":["# Instantiate the model\n","model = MyModel()\n","\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.00001)\n","\n","# Print the model architecture\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"ihfT1NiQpXtA"},"source":["**Task 2.2:** \n","\n","Why accuracy cannot be used as a loss function?\n","\n","**Your answer:** "]},{"cell_type":"markdown","metadata":{"id":"J4pg4eMotn4y"},"source":["Let's create training and validation functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GRzl5tztuMAZ"},"outputs":[],"source":["def train(model, train_loader, criterion, optimizer, device):\n","    \"\"\"\n","    Function that trains a model using the provided DataLoader, loss function (criterion), and optimizer.\n","    It iterates through the mini-batches in the DataLoader, computes the model's output, calculates the loss, and updates the model's parameters using the optimizer.\n","    \"\"\"\n","    model.train()  # Set the model to training mode\n","    running_loss = 0.0\n","\n","    for inputs, targets in train_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)  # Move the inputs and targets to the device\n","\n","        optimizer.zero_grad()  # Zero the gradients of the model's parameters\n","\n","        outputs = model(inputs)  # Compute the model's output\n","        loss = criterion(outputs, targets)  # Calculate the loss\n","\n","        loss.backward()  # Compute the gradients of the loss with respect to the model's parameters\n","        optimizer.step()  # Update the model's parameters using the optimizer\n","\n","        running_loss += loss.item()  # Accumulate the loss\n","\n","    return running_loss / len(train_loader)  # Return the average loss per mini-batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DxtVXPijuMJq"},"outputs":[],"source":["def validate(model, val_loader, criterion, device):\n","    \"\"\"\n","    Function that evaluates a model on a validation dataset using the provided DataLoader and loss function (criterion). \n","    \"\"\"\n","    model.eval()  # Set the model to evaluation mode\n","    running_loss = 0.0\n","\n","    with torch.no_grad():  # Disable gradient computation during validation\n","        for inputs, targets in val_loader:\n","            inputs, targets = inputs.to(device), targets.to(device)  # Move the inputs and targets to the device\n","\n","            outputs = model(inputs)  # Compute the model's output\n","            loss = criterion(outputs, targets)  # Calculate the loss\n","\n","            running_loss += loss.item()  # Accumulate the loss\n","\n","    return running_loss / len(val_loader)  # Return the average loss per mini-batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N1dAV0fv0Z82"},"outputs":[],"source":["def calculate_accuracy(model, data_loader, device):\n","    \"\"\"A function that calculate the accuracy of a model\"\"\"\n","    model.eval()  # Set the model to evaluation mode\n","\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():  # Disable gradient calculation during accuracy calculation\n","        for images, labels in data_loader:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            # Forward pass\n","            outputs = model(images)\n","\n","            # Calculate accuracy\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    # Calculate the overall accuracy\n","    accuracy = correct / total\n","\n","    return accuracy"]},{"cell_type":"markdown","metadata":{"id":"HEIqNx31uDAK"},"source":["Now, we have all components to train the network."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eb84yNNyjP-k"},"outputs":[],"source":["torch.manual_seed(0)\n","\n","# Set device to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Move the model to the device\n","model = model.to(device)\n","\n","# Define the number of epochs\n","num_epochs = 5\n","batch_size = 32\n","\n","history = {\n","    'train_loss': [],\n","    'val_loss': [],\n","    'train_accuracy': [],\n","    'val_accuracy': []\n","}\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    # Train the model\n","    train_loss = train(model, train_loader, criterion, optimizer, device)\n","    history['train_loss'].append(train_loss)\n","    # Calculate train accuracy\n","    train_accuracy = calculate_accuracy(model, train_loader, device)\n","    history[\"train_accuracy\"].append(train_accuracy)\n","    \n","    # Validate the model\n","    val_loss = validate(model, val_loader, criterion, device)\n","    history['val_loss'].append(val_loss)\n","    # Calculate validation accuracy\n","    val_accuracy = calculate_accuracy(model, val_loader, device)\n","    history[\"val_accuracy\"].append(val_accuracy)\n","    \n","    # Print the results for this epoch\n","    print(f\"Epoch {epoch+1}/{num_epochs}\")\n","    print(f\"Train Loss: {train_loss:.4f} | Validation Loss: {val_loss:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YcBVHh6QzsBC"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(16, 6))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(history[\"train_loss\"])\n","plt.plot(history[\"val_loss\"])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend(['Training', 'Validation'])\n","plt.title('Loss')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history[\"train_accuracy\"])\n","plt.plot(history[\"val_accuracy\"])\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend(['Training', 'Validation'])\n","plt.title('Accuracy')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"vdEVhQiO1U4W"},"source":["**Task 2.3:** \n","\n","Why training set accuracy is lower than validation set accuracy in the first epochs? Hint: training accuracy is an average over all training batches in epoch. When is validation accuracy calculated?"]},{"cell_type":"markdown","metadata":{"id":"G2Fq0yO51YF8"},"source":["**Your answer:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S3DwSuso1Lf-"},"outputs":[],"source":["test_loader = torch.utils.data.DataLoader(test_data, batch_size=64)\n","\n","test_accuracy = calculate_accuracy(model, test_loader, device)\n","print(\"Test set accuracy:\", test_accuracy)"]},{"cell_type":"markdown","metadata":{"id":"rmaLowoV4LQ_"},"source":["### Data Normalization\n","\n","neural networks work better with normalized inputs, which are around 0 (the most effective region of activation function).\n","\n","We are going to try out three different normalization methods:\n"," - **centering** (subtracting the mean),\n"," - **standardization** (subtract mean and divide by standard deviation),\n"," - **minmax** (subtract min and divide by max-min).\n","\n","For images it is sufficient to calculate statistcs for each color channel, e.g. you take mean over entire training set and also over all pixel positions. **NB**! The statistics (mean, standard deviation, min/max) must be always calculated on training set and the same values must be applied to validation and test set."]},{"cell_type":"markdown","metadata":{"id":"p_mMr2G-BiKb"},"source":["In PyTorch normalization step is usually applyied before putting data in the dataloader. Uou can use the transforms module from the `torchvision` library to apply normalization. You would typically create a `transforms.Compose` object that includes normalization and other data augmentation steps. You can check back how we performed data normalization while reading CIFAR. Or here is another example:\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NaA8Jk67CNx-"},"outputs":[],"source":["from torchvision import transforms\n","\n","mean = [0.485, 0.456, 0.406]\n","std = [0.229, 0.224, 0.225]\n","\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean, std)\n","])\n","\n","# Apply the normalization when loading your dataset\n","train_data_normalized = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","train_data_normalized = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"]},{"cell_type":"markdown","metadata":{"id":"L5bhDDKu4Ln1"},"source":["**Important note!** In Keras (with TensorFlow backend), the default format for image data is channels-last, which means the shape of the input data is (batch_size, height, width, channels). However, in **PyTorch**, the default format for image data is channels-first, which means the shape of the input data should be `(batch_size, channels, height, width)`."]},{"cell_type":"markdown","metadata":{"id":"zZOjEZcFHM3T"},"source":["### More elaborate network\n","\n","Create a network with following layers:\n","1. 3x3 convolution with 32 filters, stride 1, padding 1\n","2. batch normalization\n","3. relu\n","4. 3x3 convolution with 32 filters, stride 1, padding 0\n","5. batch normalization\n","6. relu\n","7. max pooling 2x2\n","8. dropout 0.25\n","7. flatten\n","8. Linear 64\n","5. batch normalization\n","6. relu\n","8. dropout 0.5\n","8. Linear 10\n","9. softmax"]},{"cell_type":"markdown","metadata":{"id":"pZR2aoBYHlEV"},"source":["**Task 2.4:** \n","\n","Understanding dropout\n","\n","In PyTorch, is the dropout probability interpreted as probability of keeping each node or probability of dropping?\n","\n","**Your answer:**"]},{"cell_type":"markdown","metadata":{"id":"YoOz5XMkHrRY"},"source":["**Task 2.5:** \n","\n","Create a network with given layers and calculate the intermediate shapes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OezqDtlvHIeA"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Define the neural network model as a class that inherits from nn.Module\n","class MyModel(nn.Module):\n","    def __init__(self):\n","        super(MyModel, self).__init__()\n","        ##############################################################################\n","        # TODO: Take absolute values of the gradients and maximum over channels.     #\n","        ##############################################################################\n","        self.conv1 = \n","        self.bn1 = \n","        self.relu1 = \n","        self.conv2 = \n","        self.bn2 = \n","        self.relu2 = \n","        self.pool = \n","        self.dropout1 = \n","        self.flatten = \n","        self.fc1 = \n","        self.bn3 = \n","        self.relu3 = \n","        self.dropout2 = \n","        self.fc2 = \n","        self.softmax = \n","        ##############################################################################\n","        #                             END OF YOUR CODE                               #\n","        ##############################################################################\n","        \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu1(x)\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.relu2(x)\n","        x = self.pool(x)\n","        x = self.dropout1(x)\n","        x = self.flatten(x)\n","        x = self.fc1(x)\n","        x = self.bn3(x)\n","        x = self.relu3(x)\n","        x = self.dropout2(x)\n","        x = self.fc2(x)\n","        x = self.softmax(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EBs-uQT_IDkW"},"outputs":[],"source":["model = MyModel()\n","# Define the loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Print the model architecture\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"2UKQzFH8Egge"},"source":["Be prepared that this training will take longer time than previous one. It's best to use GPU here, that's why keep in mind that you have an option to use google colab."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jdNBgru_HIlJ"},"outputs":[],"source":["# Set device to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Move the model to the device\n","model = model.to(device)\n","\n","# Define the number of epochs\n","num_epochs = 5\n","batch_size = 64\n","\n","history = {\n","    'train_loss': [],\n","    'val_loss': [],\n","    'train_accuracy': [],\n","    'val_accuracy': []\n","}\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    # Train the model\n","    train_loss = train(model, train_loader, criterion, optimizer, device)\n","    history['train_loss'].append(train_loss)\n","    # Calculate train accuracy\n","    train_accuracy = calculate_accuracy(model, train_loader, device)\n","    history[\"train_accuracy\"].append(train_accuracy)\n","    \n","    # Validate the model\n","    val_loss = validate(model, val_loader, criterion, device)\n","    history['val_loss'].append(val_loss)\n","    # Calculate validation accuracy\n","    val_accuracy = calculate_accuracy(model, val_loader, device)\n","    history[\"val_accuracy\"].append(val_accuracy)\n","    \n","    # Print the results for this epoch\n","    print(f\"Epoch {epoch+1}/{num_epochs}\")\n","    print(f\"Train Loss: {train_loss:.4f} | Validation Loss: {val_loss:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IEBaNTIdTdQO"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(16, 6))\n","\n","plt.subplot(1, 2, 1)\n","plt.plot(history[\"train_loss\"])\n","plt.plot(history[\"val_loss\"])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend(['Training', 'Validation'])\n","plt.title('Loss')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history[\"train_accuracy\"])\n","plt.plot(history[\"val_accuracy\"])\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend(['Training', 'Validation'])\n","plt.title('Accuracy')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"YOZh-O2oIJkU"},"source":["## Feature extraction\n","\n","Model trained for classification can be used in other creative ways, for example finding similar images.The hidden layer activations can be thought of as features extracted from the images. As the final goal is to classifiy images into categories, we can assume that in the last layers the features of semantically similar images are similar. That means they are close to each other according to Euclidean distance.\n"]},{"cell_type":"markdown","metadata":{"id":"AUpFOax1IYCm"},"source":["When choosing which layer features to use `Linear(64)` layer seems like a good pick - it is positioned late in the network (close to output), meaning the features should reflect the semantic meaning relatively well. Also, it has sensible dimensions - 64. We create a new model that outputs not the classification, but the `Linear(64)` layer features. We can now use `predict()` to produce features of the entire test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HvlRCt10IMX-"},"outputs":[],"source":["import numpy as np\n","\n","# Define a custom FeatureExtractor class that inherits from nn.Module\n","class FeatureExtractor(nn.Module):\n","    def __init__(self, base_model):\n","        super(FeatureExtractor, self).__init__()\n","        # Create a sequential model using layers from the base_model up to first Linear\n","        self.features = nn.Sequential(\n","            base_model.conv1,\n","            base_model.bn1,\n","            base_model.relu1,\n","            base_model.conv2,\n","            base_model.bn2,\n","            base_model.relu2,\n","            base_model.pool,\n","            base_model.dropout1,\n","            base_model.flatten,\n","            base_model.fc1\n","        )\n","    \n","    # Define the forward pass for the feature extractor\n","    def forward(self, x):\n","        return self.features(x)\n","\n","# Set up the DataLoader for the test dataset\n","testloader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False, num_workers=2)\n","\n","# Instantiate the FeatureExtractor with the base model and move it to the device (GPU/CPU)\n","extract_model = FeatureExtractor(model).to(device)\n","\n","# Initialize a list to store the extracted features\n","test_extracted_features = []\n","\n","# Loop through the test dataset without calculating gradients (speeds up the process)\n","with torch.no_grad():\n","    for i, data in enumerate(testloader, 0):\n","        # Get the inputs and labels from the test dataset\n","        inputs, labels = data\n","        # Move the inputs to the device (GPU/CPU)\n","        inputs = inputs.to(device)\n","        # Pass the inputs through the feature extractor and move the results to CPU as a NumPy array\n","        features_batch = extract_model(inputs).cpu().numpy()\n","        test_extracted_features.append(features_batch)\n","\n","# Stack the extracted features into a single NumPy array\n","test_extracted_features = np.vstack(test_extracted_features)\n","print(test_extracted_features.shape)"]},{"cell_type":"markdown","metadata":{"id":"sfAbM0KCIYQ6"},"source":["**Task 2.6:** \n","\n","Calculate euclidean distance matrix between test set images."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C5SaP7VLXQNZ"},"outputs":[],"source":["##############################################################################\n","# TODO: Calculate euclidean distance matrix between test set images higher   #\n","# level features that are extracted from the model.                          #\n","# You can either use code from the first homework or scipy squareform.       #\n","##############################################################################\n","\n","##############################################################################\n","#                             END OF YOUR CODE                               #\n","##############################################################################"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2AMahuQiXN7y"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","from torchvision.transforms.functional import to_pil_image\n","\n","plt.figure(figsize=(16, 16))\n","for i in range(10):\n","    closest = np.argsort(dists[i])[:10]\n","    for k, j in enumerate(closest):\n","        plt.subplot(10, 10, i * 10 + k + 1)\n","        plt.imshow(to_pil_image(test_data[j][0] * 0.5 + 0.5))  # denormalize the image\n","        plt.axis('off')\n","        plt.title(\"d=%0.2f\" % dists[i, j])\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"7zerInyNISru"},"source":["**Task 2.7:** \n","\n","Describe the results. Describe the mistakes it makes. A nearest-neighbour search on the input images would simply return images with most similar pixel values, how are these results different?  \n","\n","**Your answer:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2p1j0ZGypCA2"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
